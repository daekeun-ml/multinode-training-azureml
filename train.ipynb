{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Node Training with Hugging Face accelerate and AzureML\n",
    "\n",
    "Reference: https://nateraw.com/posts/multinode_training_accelerate_azureml.html\n",
    "\n",
    "This notebook shows a basic example of multi-node distributed training.\n",
    "\n",
    "[Note] Please use `Python 3.10 - SDK v2 (azureml_py310_sdkv2)` conda environment.\n",
    "\n",
    "## Step 1 - Load config file\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import json\n",
    "import ipykernel\n",
    "    \n",
    "def check_kernel():\n",
    "    kernel_id = ipykernel.connect.get_connection_file()\n",
    "\n",
    "    with open(kernel_id, 'r') as f:\n",
    "        data = json.load(f)  \n",
    "\n",
    "    if data[\"kernel_name\"] == \"\":\n",
    "        print(\"Select kernel first!\")\n",
    "    else:\n",
    "        print(f\"Kernel: {data['kernel_name']}\")\n",
    "\n",
    "check_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from logger import logger\n",
    "from datetime import datetime\n",
    "snapshot_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "with open('config.yml') as f:\n",
    "    d = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "AZURE_SUBSCRIPTION_ID = d['config']['AZURE_SUBSCRIPTION_ID']\n",
    "AZURE_RESOURCE_GROUP = d['config']['AZURE_RESOURCE_GROUP']\n",
    "AZURE_WORKSPACE = d['config']['AZURE_WORKSPACE']\n",
    "AZURE_DATA_NAME = d['config']['AZURE_DATA_NAME']    \n",
    "USE_LOWPRIORITY_VM = d['config']['USE_LOWPRIORITY_VM']\n",
    "\n",
    "use_builtin_env = d['train']['use_builtin_env']  \n",
    "azure_env_name = d['train']['azure_env_name']  \n",
    "azure_compute_cluster_name = d['train']['azure_compute_cluster_name']\n",
    "azure_compute_cluster_size = d['train']['azure_compute_cluster_size']\n",
    "num_training_nodes = d['train']['num_training_nodes']\n",
    "experiment_name = d['train']['experiment_name']    \n",
    "    \n",
    "logger.info(\"===== 1. Azure ML Training Info =====\")\n",
    "\n",
    "logger.info(f\"--- Global Config\")\n",
    "logger.info(f\"AZURE_SUBSCRIPTION_ID={AZURE_SUBSCRIPTION_ID}\")\n",
    "logger.info(f\"AZURE_RESOURCE_GROUP={AZURE_RESOURCE_GROUP}\")\n",
    "logger.info(f\"AZURE_WORKSPACE={AZURE_WORKSPACE}\")\n",
    "logger.info(f\"AZURE_DATA_NAME={AZURE_DATA_NAME}\")\n",
    "logger.info(f\"USE_LOWPRIORITY_VM={USE_LOWPRIORITY_VM}\")\n",
    "\n",
    "logger.info(f\"--- Train Config\")\n",
    "logger.info(f\"use_builtin_env={use_builtin_env}\")\n",
    "logger.info(f\"azure_env_name={azure_env_name}\")\n",
    "logger.info(f\"azure_compute_cluster_name={azure_compute_cluster_name}\")\n",
    "logger.info(f\"azure_compute_cluster_size={azure_compute_cluster_size}\")\n",
    "logger.info(f\"num_training_nodes={num_training_nodes}\")\n",
    "logger.info(f\"experiment_name={experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure workspace details\n",
    "\n",
    "To connect to a workspace, we need identifying parameters - a subscription, a resource group, and a workspace name. We will use these details in the MLClient from azure.ai.ml to get a handle on the Azure Machine Learning workspace we need. We will use the default Azure authentication for this hands-on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import time\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml import load_component\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml.entities import Data, Environment, BuildContext\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml import Output\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.core.exceptions import ResourceNotFoundError, ResourceExistsError\n",
    "\n",
    "logger.info(f\"===== 2. Training preparation =====\")\n",
    "logger.info(f\"Calling DefaultAzureCredential.\")\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    ml_client = MLClient(credential, AZURE_SUBSCRIPTION_ID, AZURE_RESOURCE_GROUP, AZURE_WORKSPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Create Compute Targets\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "def get_or_create_compute_target(ml_client, compute_cluster_name, compute_cluster_size, \n",
    "                                 num_training_nodes=1,\n",
    "                                 use_lowpriority_vm=False, update=False):\n",
    "\n",
    "    try:\n",
    "        compute = ml_client.compute.get(compute_cluster_name)\n",
    "        print(\"The compute cluster already exists! Reusing it for the current run\")\n",
    "    except Exception as ex:\n",
    "        print(\n",
    "            f\"Looks like the compute cluster doesn't exist. Creating a new one with compute size {compute_cluster_size}!\"\n",
    "        )\n",
    "        try:\n",
    "            logger.info(\"Attempt #1 - Trying to create a dedicated compute\")\n",
    "            tier = 'LowPriority' if use_lowpriority_vm else 'Dedicated'\n",
    "            compute = AmlCompute(\n",
    "                name=compute_cluster_name,\n",
    "                size=compute_cluster_size,\n",
    "                tier=tier,\n",
    "                max_instances=num_training_nodes,  # For multi node training set this to an integer value more than 1\n",
    "            )\n",
    "            ml_client.compute.begin_create_or_update(compute).wait()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "    return compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpu_compute_cluster_name = \"cpu-cluster\"\n",
    "cpu_compute_cluster_size = \"Standard_E4ds_v4\"\n",
    "gpu_compute_cluster_name = azure_compute_cluster_name\n",
    "gpu_compute_cluster_size = azure_compute_cluster_size\n",
    "\n",
    "def get_num_gpus(gpu_compute_cluster_size):\n",
    "    num_gpu_dict = {\n",
    "        \"Standard_NC24ads_A100_v4\": 1,\n",
    "        \"Standard_NC48ads_A100_v4\": 2,\n",
    "        \"Standard_NC96ads_A100_v4\": 4,\n",
    "        \"Standard_NC40ads_H100_v5\": 1,\n",
    "        \"Standard_NC80adis_H100_v5\": 2    \n",
    "    }\n",
    "    return num_gpu_dict[gpu_compute_cluster_size]\n",
    "\n",
    "num_gpus_per_node = get_num_gpus(gpu_compute_cluster_size)\n",
    "\n",
    "cpu_compute = get_or_create_compute_target(\n",
    "    ml_client, cpu_compute_cluster_name, \n",
    "    cpu_compute_cluster_size, num_training_nodes=1, update=False\n",
    ")\n",
    "\n",
    "gpu_compute = get_or_create_compute_target(\n",
    "    ml_client, gpu_compute_cluster_name, \n",
    "    gpu_compute_cluster_size, num_training_nodes=num_training_nodes, update=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Upload Data to AzureML\n",
    "\n",
    "---\n",
    "\n",
    "So, let’s get some data into AzureML! To do that, we’ll create a data-prep-step that:\n",
    "\n",
    "-   downloads compressed data from a URL,\n",
    "-   extracts it to a new location in AzureML workspace’s storage\n",
    "    Once we do this, we’ll be able to mount this data to our training run later. 💾\n",
    "\n",
    "We start off by creating a `./src` directory where all of our code will live. AzureML uploads all the files within this source directory, so we want to keep it clean.\n",
    "\n",
    "We’ll also define an experiment name, so all the jobs we run here are grouped together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "src_dir = './src'\n",
    "Path(src_dir).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Upload Script\n",
    "\n",
    "Here’s the data upload script. It simply takes in a path (to a `.tar.gz` file) and extracts it to `output_folder`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile {src_dir}/read_write_data.py\n",
    "import argparse\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input_data\", type=str)\n",
    "parser.add_argument(\"--output_folder\", type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "file = tarfile.open(args.input_data)\n",
    "output_path = os.path.join(args.output_folder)\n",
    "file.extractall(output_path)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Upload Job\n",
    "\n",
    "Now that we have some code to run, we can define the job. The below basically defines:\n",
    "\n",
    "-   Inputs: The inputs to our script. In our case it’s a `tar.gz` file stored at a URL. This will be downloaded when the job runs. We provide it to our script we wrote above via the `--input_data` flag.\n",
    "-   Outputs: The path where we will save the outputs in our workspace’s data store. We pass this to `--output_folder` in our script.\n",
    "    Environment: We use one of AzureML’s curated environments, which will result in the job starting faster. Later, for the training job, we’ll define a custom environment.\n",
    "-   Compute: We tell the job to run on our cpu-cluster.\n",
    "    Any inputs/outputs you define can be referenced via `${{inputs.<name>}}` and `${{outputs.<name>}}` in the command, so the values are passed along to the script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aml_sub = AZURE_SUBSCRIPTION_ID\n",
    "aml_rsg = AZURE_RESOURCE_GROUP\n",
    "aml_ws_name = AZURE_WORKSPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input in this case is a URL that will be downloaded\n",
    "inputs = {\n",
    "    \"pets_zip\": Input(\n",
    "        type=AssetTypes.URI_FILE,\n",
    "        path=\"https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Define output data. The resulting path will be used in run.py\n",
    "outputs = {\n",
    "    \"pets\": Output(\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "        path=f\"azureml://subscriptions/{aml_sub}/resourcegroups/{aml_rsg}/workspaces/{aml_ws_name}/datastores/workspaceblobstore/paths/pets\",\n",
    "    )\n",
    "}\n",
    "\n",
    "# Define our job\n",
    "job = command(\n",
    "    code=src_dir,\n",
    "    command=\"python read_write_data.py --input_data ${{inputs.pets_zip}} --output_folder ${{outputs.pets}}\",\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\",\n",
    "    compute=cpu_compute_cluster_name,\n",
    "    experiment_name=experiment_name,\n",
    "    display_name='data-prep-step'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Data Upload Job\n",
    "\n",
    "If everything goes smoothly, the below should launch the `data-prep` job, and spit out a link for you to watch it run.\n",
    "\n",
    "You only really need to run this job once, and then can reference it as many times as you like in the training step we are going to define in the next section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submit the command\n",
    "returned_job = ml_client.jobs.create_or_update(job)\n",
    "returned_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Train\n",
    "\n",
    "---\n",
    "\n",
    "Ok, we have some data! 🙏\n",
    "\n",
    "Let’s see how we can set up multi-node/multi-gpu training with accelerate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Training Environment\n",
    "\n",
    "For the training job, we’ll define a custom training environment, as our dependencies aren’t included in the curated environments offered by AzureML. We try to pin most of these to very specific versions so the environment won’t break in the future/if we share it with others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_or_create_environment_asset(ml_client, env_name, base_image, conda_yml=\"cloud/conda.yml\", update=False):\n",
    "    \n",
    "    try:\n",
    "        latest_env_version = max([int(e.version) for e in ml_client.environments.list(name=env_name)])\n",
    "        if update:\n",
    "            raise ResourceExistsError('Found Environment asset, but will update the Environment.')\n",
    "        else:\n",
    "            env_asset = ml_client.environments.get(name=env_name, version=latest_env_version)\n",
    "            logger.info(f\"Found Environment asset: {env_name}. Will not create again\")\n",
    "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
    "        print(f\"Exception: {e}\")        \n",
    "        env_docker_image = Environment(\n",
    "            image=base_image,\n",
    "            conda_file=conda_yml,\n",
    "            name=env_name,\n",
    "            description=\"Environment created for llm fine-tuning.\",\n",
    "        )\n",
    "        env_asset = ml_client.environments.create_or_update(env_docker_image)\n",
    "        logger.info(f\"Created/Updated Environment asset: {env_name}\")\n",
    "        \n",
    "    return env_asset\n",
    "\n",
    "def get_or_create_docker_environment_asset(ml_client, env_name, docker_dir, update=False):\n",
    "    \n",
    "    try:\n",
    "        latest_env_version = max([int(e.version) for e in ml_client.environments.list(name=env_name)])\n",
    "        if update:\n",
    "            raise ResourceExistsError('Found Environment asset, but will update the Environment.')\n",
    "        else:\n",
    "            env_asset = ml_client.environments.get(name=env_name, version=latest_env_version)\n",
    "            logger.info(f\"Found Environment asset: {env_name}. Will not create again\")\n",
    "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
    "        logger.info(f\"Exception: {e}\")\n",
    "        env_docker_image = Environment(\n",
    "            build=BuildContext(path=docker_dir),\n",
    "            name=env_name,\n",
    "            description=\"Environment created from a Docker context.\",\n",
    "        )\n",
    "        env_asset = ml_client.environments.create_or_update(env_docker_image)\n",
    "        logger.info(f\"Created Environment asset: {env_name}\")\n",
    "    \n",
    "    return env_asset\n",
    "\n",
    "def get_or_create_data_asset(ml_client, data_name, data_local_dir, update=False):\n",
    "    \n",
    "    try:\n",
    "        latest_data_version = max([int(d.version) for d in ml_client.data.list(name=data_name)])\n",
    "        if update:\n",
    "            raise ResourceExistsError('Found Data asset, but will update the Data.')            \n",
    "        else:\n",
    "            data_asset = ml_client.data.get(name=data_name, version=latest_data_version)\n",
    "            logger.info(f\"Found Data asset: {data_name}. Will not create again\")\n",
    "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
    "        data = Data(\n",
    "            path=data_local_dir,\n",
    "            type=AssetTypes.URI_FOLDER,\n",
    "            description=f\"{data_name} for fine tuning\",\n",
    "            tags={\"FineTuningType\": \"Instruction\", \"Language\": \"En\"},\n",
    "            name=data_name\n",
    "        )\n",
    "        data_asset = ml_client.data.create_or_update(data)\n",
    "        logger.info(f\"Created/Updated Data asset: {data_name}\")\n",
    "        \n",
    "    return data_asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the conda environment file we just wrote to specify additional dependencies on top of the curated `openmpi3.1.2-ubuntu18.04` docker image from AzureML.\n",
    "\n",
    "For more information on creating environments in AzureML SDK v2, check out the docs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {src_dir}/train_environment.yml\n",
    "name: aml-video-accelerate\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.9\n",
    "  - pip=24.0\n",
    "  - pip:\n",
    "    - pyarrow==18.0.0\n",
    "    - timm==1.0.11\n",
    "    - setfit==1.1.0\n",
    "    - fire==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base_image = \"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.2-cuda12.1:19\"\n",
    "# env = get_or_create_environment_asset(ml_client, azure_env_name, base_image, conda_yml=f\"{src_dir}/train_environment.yml\", update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define Training Script\n",
    "\n",
    "For our training script, we’re going to use the [complete_cv_example.py](https://github.com/huggingface/accelerate/blob/main/examples/complete_cv_example.py) script from the official [accelerate examples](https://github.com/huggingface/accelerate/tree/main/examples)\n",
    "on GitHub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! wget -O {src_dir}/train.py -nc https://raw.githubusercontent.com/huggingface/accelerate/main/examples/complete_cv_example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile {src_dir}/requirements.txt\n",
    "timm\n",
    "setfit\n",
    "fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Job\n",
    "\n",
    "The moment of truth! Let’s see if we can train an image classifier using multiple GPUs across multiple nodes on AzureML 🤞\n",
    "\n",
    "Here, we’ll define a job called `train-step` where we define:\n",
    "\n",
    "-   An input, `pets`, which points to the data store path where we stored our processed data earlier.\n",
    "-   Our training command, providing the following flags:\n",
    "    -   `--data_dir:` supplying the input reference path\n",
    "    -   `--with_tracking`: To make sure we save logs\n",
    "    -   `--checkpointing_steps epoch`: To make sure we are saving checkpoints every epoch\n",
    "    -   `--output_dir ./outputs:` Save to the `./outputs` directory, which is a special directory in AzureML meant for saving any artifacts from training.\n",
    "-   Our `training_environment` we defined above.\n",
    "-   The `distribution` as `PyTorch`, specifying `process_count_per_instance`, which is how many GPUs there are per node. (in our case, 2).\n",
    "\n",
    "For more information on how Multi-Node GPU training works on AzureML, you can refer to the [docs](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-train-distributed-gpu?view=azureml-api-2).\n",
    "\n",
    "The `command` allows user to configure the following key aspects.\n",
    "\n",
    "-   `inputs` - This is the dictionary of inputs using name value pairs to the command.\n",
    "    -   `type` - The type of input. This can be a `uri_file` or `uri_folder`. The default is `uri_folder`.\n",
    "    -   `path` - The path to the file or folder. These can be local or remote files or folders. For remote files - http/https, wasb are supported.\n",
    "        -   Azure ML `data`/`dataset` or `datastore` are of type `uri_folder`. To use `data`/`dataset` as input, you can use registered dataset in the workspace using the format '<data_name>:<version>'. For e.g Input(type='uri_folder', path='my_dataset:1')\n",
    "    -   `mode` - Mode of how the data should be delivered to the compute target. Allowed values are `ro_mount`, `rw_mount` and `download`. Default is `ro_mount`\n",
    "-   `code` - This is the path where the code to run the command is located\n",
    "-   `compute` - The compute on which the command will run. You can run it on the local machine by using `local` for the compute.\n",
    "-   `command` - This is the command that needs to be run\n",
    "    in the `command` using the `${{inputs.<input_name>}}` expression. To use files or folders as inputs, we can use the `Input` class. The `Input` class supports three parameters:\n",
    "-   `environment` - This is the environment needed for the command to run. Curated (built-in) or custom environments from the workspace can be used.\n",
    "-   `instance_count` - Number of nodes. Default is 1.\n",
    "-   `distribution` - Distribution configuration for distributed training scenarios. Azure Machine Learning supports PyTorch, TensorFlow, and MPI-based distributed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "str_command = \"\"\n",
    "\n",
    "if use_builtin_env:\n",
    "    str_env = \"azureml://registries/azureml/environments/acpt-pytorch-2.2-cuda12.1/versions/19\"  # Use Curated (built-in) Environment asset\n",
    "    str_command += \"pip install -r requirements.txt && \"\n",
    "else:\n",
    "    str_env = f\"{azure_env_name}@latest\" # Use Custom Environment asset\n",
    "    \n",
    "str_command += \"python train.py --data_dir ${{inputs.pets}} --with_tracking --checkpointing_steps epoch --output_dir ./outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define inputs, which in our case is the path from upload_cats_and_dogs.py\n",
    "inputs = dict(\n",
    "    pets=Input(\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "        path=f\"azureml://subscriptions/{aml_sub}/resourcegroups/{aml_rsg}/workspaces/{aml_ws_name}/datastores/workspaceblobstore/paths/pets/images\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define the job!\n",
    "job = command(\n",
    "    code=src_dir,\n",
    "    inputs=inputs,\n",
    "    command=str_command,\n",
    "    environment=str_env,\n",
    "    compute=gpu_compute_cluster_name,\n",
    "    instance_count=num_training_nodes,  # In this, only 2 node cluster was created.\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        # set process count to the number of gpus per node\n",
    "        # In our case (using Standard_NC12) we have 2 GPUs per node.\n",
    "        \"process_count_per_instance\": num_gpus_per_node,\n",
    "    },\n",
    "    # environment_variables={\n",
    "    #     \"MLFLOW_TRACKING_URI\": \"\"  # no use mlflow\n",
    "    # },    \n",
    "    experiment_name=experiment_name,\n",
    "    display_name='train-step'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training Job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_job = ml_client.jobs.create_or_update(job)\n",
    "display(train_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(\"\"\"Started training job. Now a dedicated Compute Cluster for training is provisioned and the environment\n",
    "required for training is automatically set up from Environment.\n",
    "\n",
    "If you have set up a new custom Environment, it will take approximately 20 minutes or more to set up the Environment before provisioning the training cluster.\n",
    "\"\"\")\n",
    "ml_client.jobs.stream(train_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the `trained_model` output is available\n",
    "job_name = train_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Step 5 (Optional) - Create model asset and get fine-tuned LLM to local folder\n",
    "\n",
    "---\n",
    "\n",
    "### Create model asset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_or_create_model_asset(ml_client, model_name, job_name, model_dir=\"outputs\", model_type=\"custom_model\", update=False):\n",
    "    \n",
    "    try:\n",
    "        latest_model_version = max([int(m.version) for m in ml_client.models.list(name=model_name)])\n",
    "        if update:\n",
    "            raise ResourceExistsError('Found Model asset, but will update the Model.')\n",
    "        else:\n",
    "            model_asset = ml_client.models.get(name=model_name, version=latest_model_version)\n",
    "            logger.info(f\"Found Model asset: {model_name}. Will not create again\")\n",
    "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
    "        logger.info(f\"Exception: {e}\")        \n",
    "        model_path = f\"azureml://jobs/{job_name}/outputs/artifacts/paths/{model_dir}/\"    \n",
    "        run_model = Model(\n",
    "            name=model_name,        \n",
    "            path=model_path,\n",
    "            description=\"Model created from run.\",\n",
    "            type=model_type # mlflow_model, custom_model, triton_model\n",
    "        )\n",
    "        model_asset = ml_client.models.create_or_update(run_model)\n",
    "        logger.info(f\"Created Model asset: {model_name}\")\n",
    "\n",
    "    return model_asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "azure_model_name = d['serve']['azure_model_name']\n",
    "model_dir = d['train']['model_dir']\n",
    "\n",
    "model = get_or_create_model_asset(ml_client, azure_model_name, job_name, model_dir, model_type=\"custom_model\", update=False)\n",
    "\n",
    "logger.info(\"===== 4. (Optional) Create model asset and get fine-tuned LLM to local folder =====\")\n",
    "logger.info(f\"azure_model_name={azure_model_name}\")\n",
    "logger.info(f\"model_dir={model_dir}\")\n",
    "logger.info(f\"model={model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the model (this is optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_model_dir = \"./artifact_downloads\"\n",
    "# os.makedirs(local_model_dir, exist_ok=True)\n",
    "# ml_client.models.download(name=azure_model_name, download_path=local_model_dir, version=model.version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
